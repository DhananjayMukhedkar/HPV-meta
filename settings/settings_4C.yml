# Dataset for pipelines outputs
OUTPUT_DATASET: Pipeline_outputs/
# Raw Input Dataset hdfs path
INPUT_ROOT_PATH: &INPUT_ROOT_RAW Raw_input/testbam
# Current run sub folder. All outputs created under this folder
RUN_FOLDER: run_test_4c

# Number of job in the pipeline (in parenthesis the name of the job in the cluster)
# job 1
# for splitting large FASTQ file
Split_Fastq:
  INPUT_ROOT : *INPUT_ROOT_RAW


# job 2 (Trimmomatic)
# for trimmomatic
Trimmomatic:
  INPUT_ROOT : *INPUT_ROOT_RAW
  OUTPUT_SINGLE : Trimmed/single
  OUTPUT_PAIRED : Trimmed/pair
  OUTPUT_UNPAIRED : Trimmed/unpair
  JAR : Tools/trimmomatic/trimmomatic-0.39.jar
  ADAPTER_PAIR : Tools/trimmomatic/adapters/TruSeq3-PE-2.fa
  ADAPTER_SINGLE : Tools/trimmomatic/adapters/TruSeq3-SE.fa
  SAVE_UNPAIRED : True
  USE_CUTADAPT : True # use True to run CUTADAPT on R2 files or False to skip
  IS_RNA : True       # use True for RNA or False for DNA
  LOGS_ROOT : Logs/Trimmomatic
  # command args
  PHRED : phred33
  LEADING : 3
  TRAILING : 3
  SLIDINGWINDOW : '4:15'
  MINLEN : 18
  THREADS : 8

# job 3 (Nextgenmap)
# for nextgenmap
Nextgenmap :
  INPUT_ROOT : Trimmed/pair
  OUTPUT_ROOT : NGM/
  REFERENCE_FILE : References/Homo_sapiens.GRCh38.dna.primary_assembly.fa
  MIN-IDENTITY : 0.95
  MIN-RESIDUES : 0.75
  THREADS : 16
  LOGS_ROOT : Logs/NGM
  VERY_FAST : True  ### True to run ngm with parameter '--very-fast'. Read NGM docs for more about this parameter.
  INSTALL_NGM : True


# job 4 (ConvertSam2BamUnmapped)
FilterSAM:
  INPUT_ROOT : NGM/
  OUTPUT_BAM : Nonhuman/bam
  THREADS : 16

# job 5
Merge:
  INPUT_ROOT : Nonhuman/bam
  OUTPUT_MERGE : Nonhuman/merged
  SAMTOOLS_PATH : Tools/samtools
  THREADS : 16

# job 6 (SortNConvert) # Warning: modify settings before running job 6.
SortConvert:
# As job 2
#  INPUT_ROOT : Extraction_nonhuman_raw
#  OUTPUT_FASTQ : *INPUT_FASTQ FASTQ
# As job 6
  INPUT_ROOT : Nonhuman/merged
  OUTPUT_FASTQ : Nonhuman/sorted

  SPLIT_PAIRS : False # True to split into separate fastq files for R1 and R2 reads for paired end files, False to create single fastq file
  THREADS : 16


# job 7 (kraken)
Kraken :
    INPUT_ROOT : Nonhuman/sorted
    OUTPUT_ROOT : Kraken/
    KRAKEN_PATH : Tools/kk2.1.2
    KRAKEN_DB_PATH : References/kraken_db/viral_bac_db
    SAVE_FULL_OUTPUT : True
    THREADS : 16

# job 8 (diamond)
# for diamond
Diamond :
  INPUT_ROOT : Nonhuman/sorted
  OUTPUT_ROOT : Diamond/
  REFERENCE_FASTA : References/HPVproteinsincludingnonoficial_201119.faa  # FASTA reference path
  DIAMOND_TOOL : Tools/diamond/v2.0.7/diamond
  OUTPUT_PREFIX : Hpv_
  # command args
  DIAMOND_RUN : blastx
  TOP : 1
  COMPRESS : 0
  OUTPUT_FORMAT: 6
  ADVANCED_TUNING : -c1
  LOGS_ROOT : Logs/Diamond

# ************************************************
# Extras


# for Postprocessing SAM files
Idxstat:
  INPUT_BAM : TCGA_Data/chunk13
  INPUT_BAI : Index/index_chunk12_13
  OUTPUT_INDEX : Index/index_chunk12_13
  OUTPUT_STAT: Index/Idxstat_chunk12_13
  THREADS : 16

# for upload from local
Upload:
  INPUT_ROOT : /media/DillnerSeqData1/uppmax/2018_F_ForeCee_NovaSeq/2018_F6_ForeCee_NovaSeq_P13704/FASTQFILES
  OUTPUT_ROOT : FASTQ/F6
  THREASHOLD_SIZE :
  MAX_SIZE_PAIR_FILTER :

# diamond post-processing scripts to create stats table
Filter_Diamond :
  INPUT_ROOT: Diamond/
  OUTPUT_ROOT: Diamond/report
  REPORT_FILE: report_diamond_run_210521_uniqueNexclusive.txt

# Human mapped reads
Unhuman:
  INPUT_ROOT : *INPUT_ROOT_RAW
  OUTPUT_BAM : Extraction_nonhuman_raw
  FILTER_BED : References/human1.bed
  THREADS : 16